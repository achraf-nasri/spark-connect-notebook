# ğŸ”Œ Spark Connect Notebook â€“ Run Spark Code Remotely with Ease

A minimal, Dockerized setup to execute **PySpark** and **SQL** code remotely on a Spark cluster using **Spark Connect**.  
Includes a simple backend API and frontend UI to interact with Spark like a remote notebook.

---

## âœ¨ Features

- ğŸ’» Run Spark code (SQL or Python) **outside the cluster**
- âš¡ Powered by **Spark Connect** (Apache Spark 3.5+)  
- ğŸ³ Fully Dockerized â€“ one command to launch everything  
- ğŸ§ª Includes backend API + frontend UI to test Spark interactions  
- ğŸ“ Example scripts included  

---

## ğŸš€ Quick Start

### 1. Clone the repo

```bash
git clone https://github.com/achraf-nasri/spark-connect-notebook.git
cd spark-connect-notebook
```

### 2. Launch the full stack

```bash
docker-compose up
```

This will start the following services:
- ğŸ§  **Spark Master**
- âš™ï¸ **2 Spark Workers**
- ğŸ”— **Spark Connect Server**
- ğŸ§ª **Backend API**
- ğŸ’» **Frontend UI**

---

## ğŸŒ Access the Components

Once started, open your browser and visit:

| Component         | URL                        |
|------------------|----------------------------|
| ğŸ’»  Notebook UI         | [http://localhost:4200](http://localhost:4200) |
| ğŸ§ª Backend API                       | [http://localhost:8000](http://localhost:8000/docs) |
| ğŸ”— Spark Connect UI | [http://localhost:4040](http://localhost:4040) |

> â„¹ï¸ These ports can be adjusted in `docker-compose.yml` if needed.

---

## ğŸ“‚ Project Structure

```
spark-connect-notebook/
â”œâ”€â”€ docker-compose.yml         # Orchestrates all services
â”œâ”€â”€ backend/                   # FastAPI backend
â”‚   â”œâ”€â”€ main.py                # API entrypoint
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/                  # UI (Angular)
â”‚   â””â”€â”€ ...                    # UI source code
â”œâ”€â”€ sample-data                # Sample files loaded to cluster for querying
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```


---

## ğŸ›  Requirements

- âœ… Docker
- âœ… Docker Compose

No need to install Spark, Java, or Python locally. Everything runs in containers.

---

## ğŸ“¬ Contact

Feel free to contact me on [LinkedIn](https://linkedin.com/in/nasriachraf) for feedback, questions, or collaboration opportunities.

---

